\chapter{Results and Discussion}
\label{chap:evaluation}

This chapter summarizes the results of the machine learning experiments and compares different machine learning models and datasets on their performance. First of all, Section \ref{sec:optimization_goal} discusses the measures which should be optimized to derive most accurate parking space maps. Furthermore, Section \ref{sec:machine_learning_results} shows the results of classical machine learning model, while Section \ref{sec:deep_learning_results} will discuss the results of the deep learning neural networks operating on raw sensor data.






\section{Optimization Goal}
\label{sec:optimization_goal}

This section should outline the processes and decisions which have been taken to determine the best performing system which would produce the most accurate parking space maps. Of course, the first interesting measure when looking at machine learning experiments is the accuracy. However, it is not always the most important one, when it comes to solving a specific problem. 

In the parking space detection scenario, which is tackled in this thesis, the overall goal is to derive accurate parking space maps using drive-by park sensing. The first step to achieve this goal is to detect parking cars, because only then it can be decided if a spot is vacant or occupied at a specific time (detecting a \emph{free space}-class is not enough as it does not determine if it is allowed to park at this spot). Therefore, the most important measure, which should be optimized, are precision and recall of the \emph{parking car}-class. As secondary goals, precision- and recall-measures of the classes \emph{overtaking situation} and \emph{other parking vehicle} should be optimized. However, these classes have only a minor occurance in the dataset and therefore, the performance is expected to be much worse than for the \emph{parking car}-class.

To be able to compare two classification results containing recall- and precision measurements, the $f-measure$ (or also called $F_1-score$) has been chosen as comparison measurement. Because it is the harmonic mean of both recall and precision it is well suited for the task. The formula to calculate the $f-measure$ is: $F_1 = 2 \times \frac{precision \times recall}{precision + recall}$.






\section{Machine Learning Results}
\label{sec:machine_learning_results}

This section discusses the results of the machine learning experiments with common machine learning models using computed feature values as input. As evaluation-method 10-fold cross validation has been chosen (see Section \ref{sec:evaluation_methods}). 
Table \ref{table:classic_ml_results} shows the results the best configurations of all tested machine learning models on the full and filtered dataset. For each machine learning model, a lot of different parameter combinations have been tested to find the best performing configuration of each model. 


\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c |}
\hline
	&
   \textbf{Accuracy} & 
   \textbf{Recall Parking Car} &
   \textbf{Precision Parking Car} \\
   &
	(full / filtered dataset) & 
	(full / filtered dataset) &
	(full / filtered dataset) \\
\hline
  \textbf{Random Forest} & & & \\
   (entropy, 1000 trees) &
   0.9600 / 0.9608 &
   0.8799 / 0.9239 &
   0.9129 / 0.9377 \\
\hline
  \textbf{Decision Tree} & & & \\
  (gini impurity) &
   0.9486 / 0.9492 &
   0.8492 / 0.8987 &
   0.8753 / 0.9176 \\
\hline
  \textbf{kNN classifier} & & & \\
  (5 nearest neighbors) &
   0.9459 / 0.9457 &
   0.8641 / 0.9175 &
   0.8618 / 0.8941 \\
\hline
  \textbf{Neural Network} & & & \\
  (5 layers - 50 units each, & & & \\
  1 million epochs) &
   0.9440 / 0.9415 &
   0.8479 / 0.9005 &
   0.8529 / 0.8891 \\
\hline
  \textbf{Support Vector Machine} & & & \\
  (kernel: radial basis function) &
   0.9423 / 0.9359 &
   0.7951 / 0.8273 &
   0.9259 / 0.9450 \\
\hline
  \textbf{Naive Bayes} & 
   0.4957 / 0.5886 &
   0.8763 / 0.8822 &
   0.4622 / 0.5915 \\
\hline

\end{tabular}
\egroup
}

\caption{Results of the best configuration (best set of parameters) of all tested classic machine learning models applied on the full and filtered dataset.}
\label{table:classic_ml_results}
\end{table}


The results clearly indicate that all tested models perform better on the parking space map filtered dataset than on the full dataset with all sensed segments. This can be explained due to a more balanced dataset, as a lot of free space segments are filtered out because they are not close to parking zones and thus not relevant.





\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 6598 & 81 & 0 & 1 \\
\hline
  \textbf{Parking Car} & 164 & 2017 & 2 & 0 \\
\hline
  \textbf{Overtaking Situation} & 14 & 35 & 17 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 37 & 18 & 0 & 5 \\
\hline

\end{tabular}
\egroup
}

\caption{Resulting confusion matrix of the random forest classifier (containing 1000 trees and using entropy as criteria) applied on the parking space map filtered dataset.}
\label{table:best_clf_confusion_matrix_filtered}
\end{table}


Comparison of all tested algorithms -> accuracy -> different feature sets -> Graphics

Description of Graphic

Maybe binary classification

Filtered Dataset -> Parking Space Maps

Stacked Classifier


\section{Deep Learning Results}
\label{sec:deep_learning_results}

Same as Machine Learning REsults







\section{Using the Segment's Surroundings to improve the Classification Results}

TODO



