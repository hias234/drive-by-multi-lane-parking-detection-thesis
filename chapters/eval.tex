\chapter{Results and Discussion}
\label{chap:evaluation}

This chapter summarizes the results of the machine learning experiments and compares different machine learning models and datasets on their performance. First of all, Section \ref{sec:optimization_goal} discusses the evaluation measures which should be optimized to derive most accurate parking space availability estimates. Furthermore, Section \ref{sec:machine_learning_results} shows the results of classical machine learning model, while Section \ref{sec:deep_learning_results} will discuss the results of the deep learning neural networks operating on raw sensor data. Finally, Section \ref{sec:using_surroundings_to_improve_results} describes how the surroundings of the samples have been used to further improve the machine learning results.






\section{Evaluation Metrics}
\label{sec:optimization_goal}

This section should outline the processes and decisions which have been taken to determine the best performing system which would produce the most accurate parking space availability estimates. 
%Of course, the first interesting measure when investigating the results of machine learning experiments is the accuracy. However, that measure is not always the most important one, when it comes to solving a specific problem. 

In the parking space detection scenario, which is tackled in this thesis, the overall goal is to derive accurate parking space availability estimates using drive-by park sensing. It is assumed that detailed parking space maps are available, thus it is sufficient to know where cars are parking to also be able to derive vacant spots (detecting a \emph{free space}-class is not enough as it does not determine if it is allowed to park at this spot). Therefore, the most important measures, which should be optimized, are \textbf{precision and recall of the \emph{parking car}-class}. As secondary goals, \textbf{precision- and recall-measures of the classes \emph{overtaking situation} and \emph{other parking vehicle}} should be optimized. \emph{Overtaking situations} are important to detect distractions which prevent deriving accurate parking space availability estimates whereas \emph{other parking vehicles}, such as parking motorcycles, should be detected because they also show that a specific parking spot is occupied. However, these classes have only a minor occurrence in the dataset. This shows that such situations occur relatively rare and therefore are not as important. 
%Furthermore, the performance is expected to be much worse than for the \emph{parking car}-class because of the few segments which are included in the datasets.

To be able to compare two classification results containing recall- and precision measurements, the \textbf{f-measure} (or also called $F_1-score$) has been chosen as comparison measurement. Because it is the harmonic mean of both recall and precision it is well suited for the task. The formula to calculate the f-measure is: $F_1 = 2 \times \frac{precision \times recall}{precision + recall}$.






\section{Traditional Machine Learning Results}
\label{sec:machine_learning_results}


\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c |}
\hline
	&
   \textbf{Accuracy} & 
   \textbf{Recall Parking Car} &
   \textbf{Precision Parking Car} \\
   &
	(full / filtered) & 
	(full / filtered) &
	(full / filtered) \\
\hline
  \textbf{Random Forest} & & & \\
   (entropy, 1000 trees) &
   0.9600 / 0.9608 &
   0.8799 / 0.9239 &
   0.9129 / 0.9377 \\
\hline
  \textbf{Decision Tree} & & & \\
  (gini impurity) &
   0.9486 / 0.9492 &
   0.8492 / 0.8987 &
   0.8753 / 0.9176 \\
\hline
  \textbf{kNN classifier} & & & \\
  (5 nearest neighbors) &
   0.9459 / 0.9457 &
   0.8641 / 0.9175 &
   0.8618 / 0.8941 \\
\hline
  \textbf{Neural Network} & & & \\
  (5 layers - 50 units each, & & & \\
  1 million epochs) &
   0.9440 / 0.9415 &
   0.8479 / 0.9005 &
   0.8529 / 0.8891 \\
\hline
  \textbf{Support Vector Machine} & & & \\
  (kernel: radial basis function) &
   0.9423 / 0.9359 &
   0.7951 / 0.8273 &
   0.9259 / 0.9450 \\
\hline
  \textbf{Naive Bayes} & 
   0.4957 / 0.5886 &
   0.8763 / 0.8822 &
   0.4622 / 0.5915 \\
\hline

\end{tabular}
\egroup
}

\caption{Overall accuracy and results for the \emph{parking car}-class of the best configuration (best set of parameters) of all tested classic machine learning models applied on the full and filtered dataset.}
\label{table:classic_ml_results}
\end{table}


This section discusses the results of the machine learning experiments with common machine learning models using computed feature values as input. As evaluation-method 10-fold cross validation has been chosen (see Section \ref{sec:evaluation_methods}). 
Table \ref{table:classic_ml_results} shows the classification results of the best configurations of all tested machine learning models on the full and filtered dataset sorted on their performance on the f-measure of the \emph{parking car}-class. For each machine learning model, many different parameter combinations have been tested to find the best performing parameter set of each model. The best performing classifier on the \emph{parking car}-class is a random forest classifier using 1000 trees and entropy as criterion for node-splitting at the individual decision trees. It leads to an accuracy of about 96\% and a f-measure value of 0.8961 and 0.9307 for the \emph{parking car}-class on the full and filtered dataset, respectively. 

Table \ref{table:best_clf_confusion_matrix_filtered} shows the confusion matrices of the random forest classifier applied on both datasets. The results clearly indicate that all tested models perform better on the parking space map filtered dataset than on the full dataset with all sensed segments. This can be explained due to a more balanced dataset, as a lot of free space segments are filtered out because they are not close to parking zones and thus not relevant.


\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 11718 & 90 & 0 & 1 \\
\hline
  \textbf{Parking Car} & 244 & 1950 & 21 & 1 \\
\hline
  \textbf{Overtaking Situation} & 63 & 82 & 62 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 54 & 14 & 0 & 1 \\
\hline

\end{tabular}
\egroup
}

\begin{center}
(a) full dataset\\
\end{center}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 6598 & 81 & 0 & 1 \\
\hline
  \textbf{Parking Car} & 164 & 2017 & 2 & 0 \\
\hline
  \textbf{Overtaking Situation} & 14 & 35 & 17 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 37 & 18 & 0 & 5 \\
\hline

\end{tabular}
\egroup
}

\begin{center}
(b) filtered dataset\\
\end{center}

\caption{Resulting confusion matrices of the random forest classifier (containing 1000 trees and using entropy as criterion for node-splitting) applied on (a) the full dataset and (b) the filtered dataset.}
\label{table:best_clf_confusion_matrix_filtered}
\end{table}


Another conclusion which can be drawn is that the performance is much worse for the classes \emph{overtaking situation} and \emph{other parking vehicle} than for the \emph{free space}- or \emph{parking car}-class. The best random forest classifier reaches a recall of 0.2575 and a precision of 0.8947 on \emph{overtaking situations}. Therefore, only about a quarter of the overtaking situations are detected. 
On the other hand, the high precision shows that only a low number of false positives are detected as overtaking situations. 
The \emph{other parking vehicle}-class has similar results: a really low recall of 0.0833 and a relatively high precision of 0.8333.
The bad results on the two classes are probably explainable because of the low number of segments in both classes included in the datasets. Thus, the variety of the data is low and a lot of different situations are not included in the dataset. Therefore, the classifiers cannot learn all different variations of overtaking situations or other parking vehicles. Another explanation is the imbalance in both datasets.






\subsection{Results for different Types of Parking Cars}

As mentioned in earlier sections, there are three different types of parking cars in the datasets: Parallel parking cars, perpendicular parking cars and angular parking cars (see Figure \ref{fig:types_of_parking_cars}). All of these different types are included in the broader \emph{parking car}-class which gets predicted by the classifiers. In this section the performance of the classification on the different types of cars is investigated.

The filtered dataset contains 1647 parallel parking cars, 339 perpendicular parking cars and 197 angular parking cars. This shows that most of the parking cars in the dataset are parallel parking cars, which can be explained because of a majority of parallel road side parking spaces in Linz, Austria. The best classifier achieves a recall of 0.9581 on parallel parking cars, 0.7964 on perpendicular parking cars and 0.8578 on angular parking cars.

Obviously, the performance of parallel parking cars is the best. That is probably caused because parallel parking cars are in comparison longer than the other types. This fact can make it easier to detect them. Furthermore, the higher number of parallel parking cars included in the dataset also enhances the performance of that type in comparison the the other types of parking cars. Perpendicular parking cars are detected less often because they are shorter in length which may lead to a more likely classification as \emph{free space}. In general, parking cars which are classified falsely are almost exclusively assigned to the \emph{free space}-class. Only two parallel parking cars have been detected as \emph{overtaking situations} while no parking cars have been detected as \emph{other parking vehicles}.




\subsection{Using Feature Subsets for Training}

The used dataset contains in total nine features. Not all of them provide the same amount of information. As discussed in Section \ref{sec:feature_analysis}, six important and three unimportant features have been identified. Training machine learning models on less (but more important) features can enhance the performance, therefore different feature subsets have been tested.

When reducing the dataset to only the six most important features, all tested machine learning models show nearly the same output as when training on the full dataset. A decision tree shows the greatest difference: it results in an f-measure on the \emph{parking car}-class of 0.8976 with all features and 0.8964 with the six most important features. Further reducing the features results in drastically decreasing accuracy. A random forest classifier using all features results in a f-measure of 0.9307. While using only six features does not change the result, using four features reduces the f-measure to 0.9147 and using two features results in an f-measure of 0.8010.

The experiments with different subsets show that using less features does not improve the performance of the classification using our datasets. The only advantage is a slightly decreased learning time for all tested models (on average the training time is 22\% lower when using only six features instead of nine). However, as the learning time is not an important evaluation metric, in the further experiments datasets with all features are used, because they result in the best classification results.



\subsection{Impact of Sampling Techniques in Order to Handle the Dataset Imbalance}

As the datasets are highly imbalanced, sampling techniques have been tested on their effect to improve the overall accuracy of the classifier and to improve the precision and recall for classes with a low number of samples. Table \ref{table:comparison_sampling_techniques} shows a comparison of different sampling techniques and their impact on different performance measures using the best classifier shown in the previous section (random forest). Experiments with other classifiers have been conducted as well but yielded in worse results on the overall accuracy.

\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
    %& Recall & Prec. & Recall & Prec.\\
    %& PC & PC & OS & OS \\
    & \textbf{No} 
    & \textbf{Over-} 
    & \textbf{Under-} 
    & \textbf{Combination} \\
    & \textbf{sampling} 
    & \textbf{sampling} 
    & \textbf{sampling} 
    & \textbf{Technique} \\
\hline
  \textbf{Overall accuracy} & 0.9608 & 0.9479 & 0.6101 & 0.9349 \\
\hline
  \textbf{Recall Free Space} & 0.9877 & 0.9664 & 0.5752 & 0.9456 \\
\hline
  \textbf{Precision Free Space} & 0.9684 & 0.9772 & 0.9738 & 0.9815 \\
\hline
  \textbf{Recall Parking Car} & 0.9239 & 0.9225 & 0.7091 & 0.9257 \\
\hline
  \textbf{Precision Parking Car} & 0.9377 & 0.9117 & 0.8336 & 0.8813 \\
\hline
  \textbf{Recall Overtaking Sit.} & 0.2575 & 0.3484 & 0.6060 & 0.4393 \\
\hline
  \textbf{Precision Overtaking Sit.} & 0.8947 & 0.3066 & 0.0417 & 0.2989 \\
\hline
  \textbf{Recall Other p. vehicles} & 0.0833 & 0.4666 & 0.9000 & 0.6166 \\
\hline
  \textbf{Precision Other p. vehicles} & 0.8333 & 0.2828 & 0.0242 & 0.2269 \\
\hline

\end{tabular}
\egroup
}

\caption{Comparison of different sampling techniques and their effect on the performance of a random forest classifier on the filtered dataset.}
\label{table:comparison_sampling_techniques}
\end{table}

All sampling techniques alter the training data by adding or deleting samples so that it is more balanced. The test data is not altered to get comparable results to the experiments where no sampling has been performed.
Over-sampling creates new synthetic samples from the existing ones, while under-sampling uses clustering techniques to find representatives for a lot of different samples. The combination technique uses both techniques in conjunction to find a compromise sampling solution. For a more detailed description of the different sampling techniques see Section \ref{sec:tested_datasets_and_handling_imbalance}. The goal of all these sampling techniques is to create a dataset where all classes have an equal number of samples. 

The results in Table \ref{table:comparison_sampling_techniques} show that all sampling techniques slightly decrease the performance of the classifier as the overall accuracy is the highest with no sampling at all. Another fact which is shown is that the sampling techniques improve the recall of the classes with a minority of samples (\emph{overtaking situations} and \emph{other parking vehicles}) while at the same time lowering the precision of these classes. This leads to the conclusion that the different sampling techniques make it more likely for the classifier to predict a class which has been a minority class, but using the sampling techniques has an equal amount of samples in the new training data.

When comparing the different sampling techniques, under-sampling clearly performs worst. This can be explained because the under-sampling algorithm deletes most samples of the majority classes in the dataset to create a balanced new dataset. The under-sampled dataset has a size of only 240 samples in total whereas the filtered dataset has a size of 8989 samples. This process removes so much information when deleting these samples that the overall performance decreases drastically. Over-sampling and the combination technique show similar results in terms of accuracy.

To conclude the results of the tests, all sampling techniques decrease the overall accuracy as well as the f-measure of the majority classes (\emph{free spaces} and \emph{parking cars}). Furthermore, the recall of the minority classes is increased while the precision is decreased. Thus, sampling techniques do help to detect more samples of the minority class while detecting less samples of the majority class. Because the primary goal of this thesis is to find a classifier with high accuracy on the \emph{parking car}-class (see Section \ref{sec:optimization_goal}), performing over- or under-sampling is counterproductive to the this goal and therefore is not considered to help in the creation of accurate parking space availability estimates.



%different feature sets

%Maybe binary classification



\section{Deep Learning Results}
\label{sec:deep_learning_results}

As deep learning outperforms classical machine learning on many different tasks, it has been evaluated and compared to classical machine learning approaches on the drive-by park sensing task, which is tackled in this thesis. Several different deep learning networks have been created with different amounts of layers and units. All of these neural networks have the raw and unprocessed sensor data as input. Table \ref{table:deep_learning_results} shows the results of the different configurations of deep learning networks as well as the best performing classifier from Section \ref{sec:machine_learning_results} to be able to easily compare the deep learning result to the classical machine learning results obtained during this thesis.



\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c |}
\hline
	&
   \textbf{Accuracy} & 
   \textbf{Recall Parking Car} &
   \textbf{Precision Parking Car} \\
   &
	(full / filtered) & 
	(full / filtered) &
	(full / filtered) \\
\hline
  \textbf{Random Forest} & & & \\
   (entropy, 1000 trees) &
   0.9600 / 0.9608 &
   0.8799 / 0.9239 &
   0.9129 / 0.9377 \\
\hline
  \textbf{Dense Deep Network} & & & \\
  (5 layers - 128 units each & & & \\
  200 epochs) &
   0.9361 / 0.9365 &
   0.7946 / 0.8987 &
   0.8524 / 0.9078 \\
\hline
  \textbf{Dense Deep Network} & & & \\
  (5 layers - 64 units each, & & & \\
  500 epochs, 20\% dropout) &
   0.9379 / 0.9313 &
   0.8434 / 0.8836 &
   0.8147 / 0.8634 \\
\hline
  \textbf{1D Convolutional Deep Network} & & & \\
  (1 convolutional layer, 2 dense layers, & & & \\
  200 epochs, 20\% dropout) &
   0.9296 / 0.9311 &
   0.7563 / 0.8027 &
   0.8248 / 0.8488 \\
\hline

\end{tabular}
\egroup
}

\caption{Overall accuracy and results for the \emph{parking car}-class of different configurations of deep learning models applied on the full and filtered dataset compared to the best classical machine learning model (random forest).}
\label{table:deep_learning_results}
\end{table}


The results shown in Table \ref{table:deep_learning_results} clearly indicate that all deep learning approaches perform worse than the random forest classifier, which was the best performing model out of the classical machine learning classifiers. The best performing deep neural network (5 hidden layers, each containing 128 units, trained in 200 epochs) gains an overall accuracy of about 93.6\% whereas the random forest classifier gets about 96.0\%. Furthermore, the recall / precision on the \emph{parking car}-class also are also worse than for the random forest classifier (0.8987 / 0.9078 for the best performing deep neural network and 0.9239 / 0.9377 for the random forest classifier). For the classes with a minority of samples, the results are similar to the random forest classifier. \emph{Overtaking situations} show a recall of 0.2272 and a precision of 0.4687 whereas \emph{other parking vehicles} get a recall of 0.1833 and a precision of 0.3793.

Deep learning gains respectable results when considering that all tests have been performed using raw sensor data. However, all of the tested configurations do not nearly perform as well as the classical machine learning approaches. Therefore, it can be concluded that for the drive-by parking detection task, classical machine learning models using pre-computed feature values are better suited than deep neural networks operating on raw sensor data.



\section{Using the Segment's Surroundings to improve the Classification Results}
\label{sec:using_surroundings_to_improve_results}

To further improve the classification results, a custom classification process has been implemented which should help to increase the accuracy and especially the recall and precision of the \emph{parking car}-class. The classification process should produce better results because it is including the information of surrounding samples when classifying.

In a first step a basic classification result is obtained using the best performing classifier from Section \ref{sec:machine_learning_results} (random forest). 
 Then a new dataset is created containing all features as well as the class label predicted by the random forest classifier. Furthermore, the class label and the corresponding distances from the sensing vehicles of the $k$ surrounding samples are also appended to the dataset. For the number $k$ of included surrounding segments, several values have been tested to find the best performing value. In a final step another classifier is trained on the new dataset. All machine learning models which have been discussed in Section \ref{sec:machine_learning_results} have been tested on this new dataset. A more detailed description of the process can be found in Section \ref{sec:improv_classification_surrounding_segments}.
 
\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c |}
\hline
    & \textbf{Normal} 
    & \textbf{Improved Two Staged} 
    \\
    & \textbf{Random Forest} 
    & \textbf{Custom Classifier} 
    \\
    & (entropy, 1000 trees)
    & (10 surrounding samples)
    \\
\hline
  \textbf{Overall accuracy} & 0.9608 & 0.9652 \\
\hline
  \textbf{Recall Free Space} & 0.9877 & 0.9877 \\
\hline
  \textbf{Precision Free Space} & 0.9684 & 0.9730 \\
\hline
  \textbf{Recall Parking Car} & 0.9239 & 0.9381 \\
\hline
  \textbf{Precision Parking Car} & 0.9377 & 0.9429 \\
\hline
  \textbf{Recall Overtaking Sit.} & 0.2575 & 0.3030 \\
\hline
  \textbf{Precision Overtaking Sit.} & 0.8947 & 0.9523 \\
\hline
  \textbf{Recall Other p. vehicles} & 0.0833 & 0.1833 \\
\hline
  \textbf{Precision Other p. vehicles} & 0.8333 & 0.7333 \\
\hline

\end{tabular}
\egroup
}

\caption{Comparison of the best performing random forest classifier to the best configuration of the proposed two staged classification technique  (two random forests and using 10 surrounding samples) on the filtered dataset.}
\label{table:comparison_random_forest_custom_classifier}
\end{table}
 
 
Table \ref{table:comparison_random_forest_custom_classifier} shows the comparison of the normal random forest classifier and the enhanced two-staged technique using information from the surrounding samples. The overall accuracy and the precision/recall values of every class are compared. The enhanced classification technique performs better in almost every performance measure. While the overall accuracy is increased by about 0.5\%, especially the recall and precision of the \emph{parking car}-class gets improved. The f-measure of the \emph{parking car}-class for the normal random forest is 0.9307, the improved classification technique increases this measurement by about one percent to 0.9405. In absolute numbers this means that 31 parking cars are detected which have been missed by the normal random forest classifier. Table \ref{table:surrounding_classifier_confusion_matrix} shows the detailed results in form of a confusion matrix.

The improved classification technique especially helps with classifying perpendicular and angular parking cars. While the normal random forest classifier already detects about 95.8\% of the parallel parking cars, the recall for perpendicular and angular parking cars are only 79.6\% and 85.7\%, respectively. The improved classifier increases the recall of all classes. It reaches 96.2\% for parallel parking cars, 84.6\% for perpendicular parking cars and 88.3\% for angular parking cars. 

The minority classes are also improved

 










\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 6598 & 79 & 0 & 3 \\
\hline
  \textbf{Parking Car} & 133 & 2048 & 1 & 1 \\
\hline
  \textbf{Overtaking Situation} & 14 & 32 & 20 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 36 & 13 & 0 & 11 \\
\hline

\end{tabular}
\egroup
}

\caption{Confusion Matrix of the best found configuration of the proposed two staged classification technique (two random forests and using 10 surrounding samples).}
\label{table:surrounding_classifier_confusion_matrix}
\end{table}

