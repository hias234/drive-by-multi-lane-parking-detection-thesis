\chapter{Results and Discussion}
\label{chap:evaluation}

This chapter summarizes the results of the machine learning experiments and compares different machine learning models and datasets. First of all, Section \ref{sec:optimization_goal} discusses the evaluation metrics used to derive most accurate parking space availability estimates. Section \ref{sec:machine_learning_results} shows the results of classical machine learning models applied to the feature set (see Section \ref{sec:feature_calculation}), while Section \ref{sec:deep_learning_results} discusses the results of deep learning neural networks operating on raw sensor data. Finally, Section \ref{sec:using_surroundings_to_improve_results} describes a proposed two-staged classification process which further improves the classification results using the surroundings of the parking situation which should be classified.






\section{Evaluation Metrics}
\label{sec:optimization_goal}

This section should outline the processes and decisions which have been taken to determine the best performing system which would produce the most accurate parking space availability estimates.

In the parking space detection scenario the overall goal is to derive accurate parking space availability estimates using drive-by parking space sensing. It is assumed that detailed parking space maps are available which show locations of parking spaces. It is then sufficient to know where cars are parking to also be able to derive vacant spots. Detecting a \emph{free space} is not enough as it does not determine whether it is allowed to park at this spot. Overall we aim at differentiating between the following classes:

\begin{itemize}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}

\item free parking space
\item occupied parking space - parking car
\item overtaking situation
\item occupied parking space - other parking vehicle.

\end{itemize}

The most important measures are \textbf{precision and recall of the \emph{parking car}-class}. As secondary goals, \textbf{precision- and recall-measures of the classes \emph{overtaking situation} and \emph{other parking vehicle}} should be considered. \emph{Overtaking situations} are important distractions which prevent deriving accurate parking space availability estimates whereas \emph{other parking vehicles}, such as parking motorcycles, should be detected because they also show that a specific parking spot is occupied. However, these classes have only a minor occurrence in the dataset. This fact indicates that such situations occur relatively rare and therefore are not as important. Further measures considered are the overall accuracy, precision, and recall of the \emph{free space}-class as well as the necessary training time needed for each machine learning model.

The accuracy-, precision-, and recall-measures are defined as follows:

\[ accuracy = \frac{tp + tn}{tp + tn + fp + fn} \qquad precision = \frac{tp}{tp + fp} \qquad recall = \frac{tp}{tp + fn}, \]



where $tp$ are true positives (correctly classified samples), $fp$ are false positives (samples which are wrongly classified as the target class), and $fn$ are false negatives (samples of the target class which are wrongly classified as another class).

To be able to compare two classification results containing recall- and precision values together, the \textbf{f-measure} (or also called $F_1$-score) is chosen. Because it is the harmonic mean of both recall and precision, it is well suited for the task. The formula to calculate the f-measure is as follows: 

\[ F_1 = 2 \times \frac{precision \times recall}{precision + recall}. \]






\section{Traditional Machine Learning Results}
\label{sec:machine_learning_results}


\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c |}
\hline
	&
   \textbf{Accuracy} & 
   \textbf{Recall Parking Car} &
   \textbf{Precision Parking Car} \\
   &
	(full / filtered) & 
	(full / filtered) &
	(full / filtered) \\
\hline
  \textbf{Random Forest} & & & \\
   (entropy, 1000 trees) &
   0.9600 / 0.9608 &
   0.8799 / 0.9239 &
   0.9129 / 0.9377 \\
\hline
  \textbf{Decision Tree} & & & \\
  (gini impurity) &
   0.9485 / 0.9486 &
   0.8492 / 0.8987 &
   0.8745 / 0.9155 \\
\hline
  \textbf{kNN classifier} & & & \\
  (5 nearest neighbors) &
   0.9459 / 0.9457 &
   0.8641 / 0.9175 &
   0.8618 / 0.8941 \\
\hline
  \textbf{Neural Network} & & & \\
  (5 layers - 50 units each, & & & \\
  1 million epochs) &
   0.9440 / 0.9415 &
   0.8479 / 0.9005 &
   0.8529 / 0.8891 \\
\hline
  \textbf{Support Vector Machine} & & & \\
  (kernel: radial basis function) &
   0.9423 / 0.9359 &
   0.7951 / 0.8273 &
   0.9259 / 0.9450 \\
\hline
  \textbf{Naive Bayes} & 
   0.4957 / 0.5886 &
   0.8763 / 0.8822 &
   0.4622 / 0.5915 \\
\hline

\end{tabular}
\egroup
}

\caption{Overall accuracy and recall and precision for the \emph{parking car}-class of the best configuration (best set of parameters) of all tested classic machine learning models applied on the full and filtered dataset.}
\label{table:classic_ml_results}
\end{table}


This section discusses the results of the machine learning experiments with common machine learning models using computed feature values as input. The following models have been evaluated: Naive Bayes classifiers, support vector machines, neural networks, kNN classifiers, decision trees, and random forests (see Section \ref{sec:machine_learning_models}). As evaluation-method 10-fold cross validation has been chosen (see Section \ref{sec:evaluation_methods}). 
Table \ref{table:classic_ml_results} shows the classification results of the best configurations of all tested machine learning models on the full and filtered dataset sorted on their performance on the f-measure of the \emph{parking car}-class. For each machine learning model, many different parameter combinations have been tested to find the best performing parameter set of each model. The best performing classifier on the \emph{parking car}-class is a random forest classifier using 1000 trees and entropy as criterion for node-splitting at the individual decision trees. It leads to an accuracy of about 96\% and an f-measure value of 0.8961 and 0.9307 for the \emph{parking car}-class on the full and filtered dataset, respectively. 

Table \ref{table:best_clf_confusion_matrix_filtered} shows the confusion matrices of the random forest classifier applied to both datasets. The results clearly indicate that all tested models perform better on the parking space map filtered dataset than on the full dataset with all sensed segments. This can be explained by the more balanced filtered dataset, as a lot of free space segments are filtered out because they are not close to parking zones and thus not relevant.
As the amount of samples is far more balanced with the filtered dataset, the bias towards free spaces is less present and it is more likely for a sample to be classified as parking car. This fact increases the recall and precision of the \emph{parking car}-class which is the primary objective.


\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 11718 & 90 & 0 & 1 \\
\hline
  \textbf{Parking Car} & 244 & 1950 & 21 & 1 \\
\hline
  \textbf{Overtaking Situation} & 63 & 82 & 62 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 54 & 14 & 0 & 1 \\
\hline

\end{tabular}
\egroup
}

\begin{center}
(a) full dataset\\
\end{center}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 6598 & 81 & 0 & 1 \\
\hline
  \textbf{Parking Car} & 164 & 2017 & 2 & 0 \\
\hline
  \textbf{Overtaking Situation} & 14 & 35 & 17 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 37 & 18 & 0 & 5 \\
\hline

\end{tabular}
\egroup
}

\begin{center}
(b) filtered dataset\\
\end{center}

\caption{Confusion matrices of the random forest classifier (containing 1000 trees and using entropy as criterion for node-splitting) applied on (a) the full dataset and (b) the filtered dataset.}
\label{table:best_clf_confusion_matrix_filtered}
\end{table}


Another conclusion which can be drawn is that the performance of the classes \emph{overtaking situation} and \emph{other parking vehicle} is much worse than of the \emph{free space}- or \emph{parking car}-class. The best random forest classifier reaches a recall of 0.2575 and a precision of 0.8947 on \emph{overtaking situations}. Only about a quarter of the overtaking situations are detected. 
On the other hand, the high precision shows that only a low number of false positives are detected as overtaking situations. 
The \emph{other parking vehicle}-class has similar results: a low recall of 0.0833 and a relatively high precision of 0.8333.
A possible reason for the bad results of the two classes is the low number of segments in both classes included in the datasets. The variety of the data is low and a lot of different situations are not included in the dataset. Therefore, the classifiers cannot learn all different variations of overtaking situations or other parking vehicles.

The random forest, which performs best, requires the highest evaluation time (training and prediction for all 10 folds) of about 230 seconds. The evaluation time of the other classifiers are considerably shorter. However, almost all of the 230 seconds were used for training the random forest. Once the system is trained, it can predict parking situations within milliseconds. Thus, the long training time of the random forest does not have an impact on the running system.





\subsection{Results for Different Types of Parking Cars}

As mentioned in earlier sections, there are three different types of parking cars in the datasets: Parallel parking cars, perpendicular parking cars, and angular parking cars (see Figure \ref{fig:types_of_parking_cars}). All of these different types are included in the broader \emph{parking car}-class which gets predicted by the classifiers. In this section the performance of the classification of the different types of cars is investigated.

%The filtered dataset contains 1647 parallel parking cars, 339 perpendicular parking cars, and 197 angular parking cars. The majority of parking cars in the dataset are parallel parking cars, which reflects the large number of parallel road side parking spaces in Linz, Austria. The best classifier achieves a recall of 0.9581 of parallel parking cars, 0.7964 of perpendicular parking cars, and 0.8578 of angular parking cars.

Table \ref{table:result_different_types_cars} shows the frequency of the different types of parking cars in the dataset as well as the achieved recall when classifying them.
As expected, the performance of parallel parking cars is the best. One possible reason is the length of the parking space. Parallel parking cars are in comparison longer than the other types. This fact can make it easier to detect them. Furthermore, the higher number of parallel parking cars included in the dataset also enhances the performance of that type in comparison to the other types of parking cars. Perpendicular parking cars are detected less often because they are shorter in length which may lead to a more likely classification as \emph{free space}. In general, parking cars which are classified falsely are almost exclusively assigned to the \emph{free space}-class. Only two parallel parking cars have been detected as \emph{overtaking situations} while no parking cars have been detected as \emph{other parking vehicles}.

\begin{table}


%\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c |}
\hline
	&
   \textbf{Total Number of Samples} & 
   \textbf{Recall}  \\
\hline
   \textbf{Parallel Parking Car}	&
   1647 & 
   0.9581 \\
\hline
   \textbf{Perpendicular Parking Car}	&
   339 & 
   0.7964 \\
\hline
   \textbf{Angular Parking Car}	&
   197 & 
   0.8578 \\
\hline

\end{tabular}
\egroup
%}

\caption{Frequency of different types of parking cars in our dataset and the achieved recall of our best random forest classifier.}
\label{table:result_different_types_cars}
\end{table}




\subsection{Using Feature Subsets for Training}

The used dataset contains in total nine features. Not all of them provide the same amount of information. As discussed in Section \ref{sec:feature_analysis}, six important and three not important features have been identified. Training machine learning models on less (but more important) features can enhance the performance, therefore different feature subsets have been tested. In the following, only the filtered dataset is used.

When reducing the dataset to only the six most important features, all tested machine learning models show nearly the same results as when trained with all nine features. A decision tree shows the greatest difference when used on the two datasets: it results in an f-measure on the \emph{parking car}-class of 0.8976 with all features and 0.8964 with the six most important features. Further reducing the features results in drastically decreasing accuracy.
Table \ref{table:result_subsets} shows the f-measure of parking cars when using different feature subsets on a random forest classifier.
While using only six features instead of all nine does not change the result, using four features reduces the f-measure to 0.9147 and using two features results in an f-measure of 0.8010.

\begin{table}


%\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c |}
\hline
	&
   \textbf{F-Measure of Parking Cars} \\
\hline
   \textbf{All nine features}	&
   0.9307  \\
\hline
   \textbf{Six most important features}	&
   0.9307 \\
\hline
   \textbf{Four most important features}	&
   0.9147 \\
\hline
   \textbf{Two most important features}	&
   0.8010 \\
\hline

\end{tabular}
\egroup
%}

\caption{Classification results of the best performing random forest using different feature subsets.}
\label{table:result_subsets}
\end{table}



The experiments with different subsets show that using fewer features does not improve the performance of the classification using our datasets. The only advantage is a slightly decreased training time for all tested models (on average the training time is 22\% lower when using only six features instead of nine). However, as the training time is not an important evaluation metric, in the further experiments datasets with all features are used, because they result in the best classification results.



\subsection{Impact of Sampling Techniques in Order to Handle the Dataset Imbalance}

As the datasets are highly imbalanced, sampling techniques are tested and compared in terms of overall accuracy of the classifier and precision and recall of classes with a low number of samples. Table \ref{table:comparison_sampling_techniques} shows a comparison of different sampling techniques and their impact on the different performance measures using the best classifier shown in the previous section (random forest). Experiments with other classifiers have been conducted as well but yielded in worse results on the overall accuracy.

All sampling techniques alter the training data by adding or deleting samples so that it is more balanced. The test data are not altered in order to get results that can be compared to the experiments where no sampling has been performed.
Over-sampling creates new synthetic samples from the existing ones, while under-sampling uses clustering techniques to find representatives for a set of different samples. The combination technique uses both basic techniques to find a compromise sampling solution. For a more detailed description of the different sampling techniques see Section \ref{sec:tested_datasets_and_handling_imbalance}. The goal of all these sampling techniques is to create a dataset where the number of samples of every class is similar. 

The results in Table \ref{table:comparison_sampling_techniques} show that all sampling techniques slightly decrease the performance of the classifier as the overall accuracy is the highest with no sampling at all. Another fact which is shown is that the sampling techniques improve the recall of the classes with a minority of samples (\emph{overtaking situations} and \emph{other parking vehicles}) while at the same time lowering the precision of these classes. This leads to the conclusion that the different sampling techniques make it more likely for the classifier to predict a class which has been a minority class.

\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
    %& Recall & Prec. & Recall & Prec.\\
    %& PC & PC & OS & OS \\
    & \textbf{No} 
    & \textbf{Over-} 
    & \textbf{Under-} 
    & \textbf{Combination} \\
    & \textbf{sampling} 
    & \textbf{sampling} 
    & \textbf{sampling} 
    & \textbf{Technique} \\
\hline
  \textbf{Overall accuracy} & 0.9608 & 0.9479 & 0.6101 & 0.9349 \\
\hline
  \textbf{Recall Free Space} & 0.9877 & 0.9664 & 0.5752 & 0.9456 \\
\hline
  \textbf{Precision Free Space} & 0.9684 & 0.9772 & 0.9738 & 0.9815 \\
\hline
  \textbf{Recall Parking Car} & 0.9239 & 0.9225 & 0.7091 & 0.9257 \\
\hline
  \textbf{Precision Parking Car} & 0.9377 & 0.9117 & 0.8336 & 0.8813 \\
\hline
  \textbf{Recall Overtaking Sit.} & 0.2575 & 0.3484 & 0.6060 & 0.4393 \\
\hline
  \textbf{Precision Overtaking Sit.} & 0.8947 & 0.3066 & 0.0417 & 0.2989 \\
\hline
  \textbf{Recall Other p. vehicles} & 0.0833 & 0.4666 & 0.9000 & 0.6166 \\
\hline
  \textbf{Precision Other p. vehicles} & 0.8333 & 0.2828 & 0.0242 & 0.2269 \\
\hline
  \textbf{Evaluation Time [s]} & 230.38 & 637.63 & 82.17 & 560.96 \\
\hline

\end{tabular}
\egroup
}

\caption{Comparison of different sampling techniques and their effect on the performance of a random forest classifier on the filtered dataset.}
\label{table:comparison_sampling_techniques}
\end{table}

When comparing the different sampling techniques, under-sampling clearly performs worst. This can be explained as the under-sampling algorithm deletes most samples of the well-performing majority classes in the dataset to create a balanced new dataset. The under-sampled dataset has a size of only 240 samples in total whereas the whole filtered dataset has a size of 8989 samples. This process removes so much information by deleting these samples that the overall performance decreases drastically. Over-sampling and the combination technique show similar results in terms of accuracy.

To conclude the results of the tests, all sampling techniques decrease the overall accuracy as well as the f-measure of the majority classes (\emph{free spaces} and \emph{parking cars}). Furthermore, the recall of the minority classes is increased while the precision is decreased. Thus, sampling techniques do help to detect more samples of the minority class while detecting less samples of the majority class. Because the primary goal of this thesis is to find a classifier with high accuracy on the \emph{parking car}-class (see Section \ref{sec:optimization_goal}), performing over- or under-sampling is counter-productive to the this goal and therefore is not considered to help in the creation of accurate parking space availability estimates.



%different feature sets

%Maybe binary classification



\section{Deep Learning Results}
\label{sec:deep_learning_results}

As deep learning outperforms classical machine learning for many different tasks, it has been evaluated and compared to classical machine learning approaches applied to the drive-by parking space sensing task. Several different deep learning networks have been created with different amounts of layers and units. All of these neural networks use the raw and unprocessed sensor data as input. Table \ref{table:deep_learning_results} compares the results of the different configurations of deep learning networks as well as the best performing classifier from Section \ref{sec:machine_learning_results}, the random forest. 

To find the best performing configuration, several different parameters have been tested. Table \ref{table:deep_learning_results} shows only the configurations that yielded best results for normal deep neural networks, neural networks with dropout, and neural networks that use convolutional layers. Networks using five hidden layers have been tested with 32 to 128 units each. For the number of learning epochs (times that the training dataset is used to train the neural network) 50 to 200 epochs have been tested.
A normal deep learning network with five layers and 128 units each trained in 200 epochs gained the best results with an f-measure of 0.8792 for the \emph{parking car}-class. 

In addition to normal deep learning networks, two strategies for improving performance have been evaluated. Using dropout can help deep learning networks to avoid overfitting. In the experiments 10\%, 20\% and 50\% dropout have been tested, but the results were worse in all cases. Thus, dropout is not considered to help improving the classification results. Another strategy which has been evaluated, is using convolutional layers. In domains like image recognition convolution greatly improves the performance. However, in our case the convolutional deep learning network performed much worse than the other configurations.

\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c |}
\hline
	&
   \textbf{Accuracy} & 
   \textbf{Recall Parking Car} &
   \textbf{Precision Parking Car} \\
   &
	(full / filtered) & 
	(full / filtered) &
	(full / filtered) \\
\hline
  \textbf{Random Forest} & & & \\
   (entropy, 1000 trees) &
   0.9600 / 0.9608 &
   0.8799 / 0.9239 &
   0.9129 / 0.9377 \\
\hline
  \textbf{Dense Deep Network} & & & \\
  (5 layers - 128 units each & & & \\
  200 epochs) &
   0.9369 / 0.9344 &
   0.7969 / 0.8405 &
   0.8478 / 0.9124 \\
\hline
  \textbf{Dense Deep Network} & & & \\
  (5 layers - 128 units each, & & & \\
  200 epochs, 10\% dropout) &
   0.9397 / 0.9355 &
   0.8158 / 0.8680 &
   0.8444 / 0.8913 \\
\hline
  \textbf{1D Convolutional Deep Network} & & & \\
  (1 convolutional layer, 2 dense layers, & & & \\
  200 epochs) &
   0.9330 / 0.9216 &
   0.7582 / 0.8334 &
   0.8484 / 0.8735 \\
\hline

\end{tabular}
\egroup
}

\caption{Overall accuracy and recall and precision for the \emph{parking car}-class of different configurations of deep learning models applied on the full and filtered dataset compared to the best classical machine learning model (random forest).}
\label{table:deep_learning_results}
\end{table}

The results shown in Table \ref{table:deep_learning_results} clearly indicate that all deep learning approaches perform worse than the random forest classifier, which was the best performing model out of the classical machine learning classifiers. The best performing deep neural network gains an overall accuracy of about 93.6\% whereas the random forest classifier gets about 96.0\%. Furthermore, the recall / precision on the \emph{parking car}-class are also worse than for the random forest classifier (0.8987 / 0.9078 for the best performing deep neural network and 0.9239 / 0.9377 for the random forest classifier). For the classes with a minority of samples, the results are similar to the random forest classifier. \emph{Overtaking situations} show a recall of 0.3239 and a precision of 0.2452 whereas \emph{other parking vehicles} get a recall of 0.0909 and a precision of 0.1612.

Deep learning gains respectable results when considering that all tests have been performed using raw sensor data. However, all of the tested configurations cannot reach the quality of the random forest and the other classical machine learning approaches. Therefore, it can be concluded that for the drive-by parking detection task, classical machine learning models using pre-computed feature values are better suited than deep neural networks operating on raw sensor data.






\section{Using Segment Surroundings to Improve the Classification Results}
\label{sec:using_surroundings_to_improve_results}

To further improve the classification results, a custom classification process has been implemented which should help to increase the accuracy and especially the recall and precision of the \emph{parking car}-class. The proposed classification process is expected to yield better results because it is also including the information of surrounding segments when classifying instead of only considering the properties of the segment which gets classified.

In a first step a basic classification result is obtained using the best performing random forest classifier.
Then a new dataset is created containing all features as well as the class label predicted by the random forest classifier. 
Furthermore, features which are calculated using the surrounding segments are appended to the dataset (for more information see Section \ref{sec:improv_classification_surrounding_segments} and Figure \ref{fig:surrounding_segments_classification_process}).
%Furthermore, the class label and the corresponding distance values of the $k$ surrounding segments are also appended to the dataset. 
%\todo{hinzufügen einer grafik, die dieses neue datenset zeigt, d.h. wie die surrounding samples hinzufegügt werden}
 Using this information, the second classifier should be able to include the surrounding segments into its prediction process (e.g. if all surrounding segments, which are parking cars, have a distance of 3m to the sensing vehicle, then it is likely that the current sample is a parking car if it is also about 3m from the sensing vehicle). For the number $k$ of included surrounding segments, several values have been tested to find the best performing value.
Table \ref{table:surrounding_different_k_surrounding_segments} shows a comparison of the performance using different values for $k$.
In a final step a second classifier is trained on the newly created dataset. All machine learning models which have been discussed in Section \ref{sec:machine_learning_results} have been tested on this new dataset.


\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
    &
    & 
   \textbf{Recall} &
   \textbf{Precision} &
   \textbf{F-Measure} \\
    &
   \textbf{Accuracy} & 
   \textbf{Parking Car} &
   \textbf{Parking Car} &
   \textbf{Parking Car} \\
\hline
  \textbf{10 surrounding samples} & 0.9652 & 0.9381 & 0.9429 & 0.9404 \\
\hline
  \textbf{20 surrounding samples} & 0.9649 & 0.9372 & 0.9419 & 0.9395\\
\hline
  \textbf{40 surrounding samples} & 0.9651 & 0.9363 & 0.9428 & 0.9395 \\
\hline
  \textbf{50 surrounding samples} & 0.9648 & 0.9363 & 0.9419 & 0.9390 \\
\hline
  \textbf{5 surrounding samples} & 0.9645 & 0.9358 & 0.9423 & 0.9390 \\
\hline
  \textbf{30 surrounding samples} & 0.9645 & 0.9340 & 0.9418 & 0.9378 \\
\hline
  \textbf{Random forest classifier} & 0.9608 & 0.9239 & 0.9377 & 0.9307 \\
\hline

\end{tabular}
\egroup
}

\caption{Comparison of the performance when taking different values for the number of surrounding samples ($k$) in the two-staged classification process. The table is sorted descending using the f-measure of the \emph{parking car}-class.}
\label{table:surrounding_different_k_surrounding_segments}
\end{table}


\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c |}
\hline
    & \textbf{Normal} 
    & \textbf{Improved Two Staged} 
    \\
    & \textbf{Random Forest} 
    & \textbf{Custom Classifier} 
    \\
    & (entropy, 1000 trees)
    & (10 surrounding segments)
    \\
\hline
  \textbf{Overall accuracy} & 0.9608 & 0.9652 \\
\hline
  \textbf{Recall Free Space} & 0.9877 & 0.9877 \\
\hline
  \textbf{Precision Free Space} & 0.9684 & 0.9730 \\
\hline
  \textbf{Recall Parking Car} & 0.9239 & 0.9381 \\
\hline
  \textbf{Precision Parking Car} & 0.9377 & 0.9429 \\
\hline
  \textbf{Recall Overtaking Sit.} & 0.2575 & 0.3030 \\
\hline
  \textbf{Precision Overtaking Sit.} & 0.8947 & 0.9523 \\
\hline
  \textbf{Recall Other p. vehicles} & 0.0833 & 0.1833 \\
\hline
  \textbf{Precision Other p. vehicles} & 0.8333 & 0.7333 \\
\hline
  \textbf{Evaluation Time [s]} & 230.38 & 476.06 \\
\hline

\end{tabular}
\egroup
}

\caption{Comparison of the best performing random forest classifier to the best configuration of the proposed two staged classification technique  (two random forests and using 10 surrounding samples) on the filtered dataset.}
\label{table:comparison_random_forest_custom_classifier}
\end{table}
 
 
Table \ref{table:comparison_random_forest_custom_classifier} shows the comparison of the normal random forest classifier and the enhanced two-staged technique using information from the surrounding segments (10 surrounding segments perform best). The overall accuracy and the precision/recall values of every class are compared. The enhanced classification technique performs better in almost every performance measure. While the overall accuracy is increased by about 0.5\%, especially the recall and precision of the \emph{parking car}-class get improved. The f-measure of the \emph{parking car}-class for the normal random forest is 0.9307. The improved classification technique increases this measurement by about one percent to 0.9405. In absolute numbers this means that 31 parking cars are detected which have been missed by the normal random forest classifier. Table \ref{table:surrounding_classifier_confusion_matrix} shows the detailed results in form of a confusion matrix.


\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 6598 & 79 & 0 & 3 \\
\hline
  \textbf{Parking Car} & 133 & 2048 & 1 & 1 \\
\hline
  \textbf{Overtaking Situation} & 14 & 32 & 20 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 36 & 13 & 0 & 11 \\
\hline

\end{tabular}
\egroup
}

\caption{Confusion Matrix of the best found configuration of the proposed two staged classification technique (two random forests and using 10 surrounding samples).}
\label{table:surrounding_classifier_confusion_matrix}
\end{table}


The improved classification technique especially helps with classifying perpendicular and angular parking cars. While the normal random forest classifier already detects about 95.8\% of the parallel parking cars, the recall for perpendicular and angular parking cars are only 79.6\% and 85.7\%, respectively. The improved classifier increases the recall of all classes. It reaches 96.2\% for parallel parking cars, 84.6\% for perpendicular parking cars and 88.3\% for angular parking cars. 

The performance of predicting the minority classes is also slightly improved. \emph{Overtaking situations} have a recall of 0.3030 instead of 0.2575 with the normal classifier. Its precision is also increased from 0.8947 to 0.9523. \emph{Other parking vehicles} are also detected more likely. The improved recall is 0.1833 whereas the recall of the normal random forest is 0.0833. The only measurement which is worse with the proposed two staged technique is the precision of \emph{other parking cars}. The new technique results in a value of 0.7333 instead of 0.8333.

To further improve the classification performance of all classes, a bigger dataset with more variety in the recorded situations would be beneficial. Especially for detecting overtaking vehicles and parking motorcycles- and bicycles, more different samples would increase the accuracy as with the current dataset these classes have only a minor occurrence. 

Altogether the proposed two staged approach outperforms all other tested classifiers due to the increased amount of information which has been taken into account. It improves the overall accuracy by about 0.5\% and the f-measure of the \emph{parking car}-class by about 1.0\%. 

%\todo{ideen, ansätze wie man overtaking + other parking cars verbessern könnte als ausblick}





