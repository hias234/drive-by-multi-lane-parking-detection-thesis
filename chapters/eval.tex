\chapter{Results and Discussion}
\label{chap:evaluation}

This chapter summarizes the results of the machine learning experiments and compares different machine learning models and datasets on their performance. First of all, Section \ref{sec:optimization_goal} discusses the measures which should be optimized to derive most accurate parking space availability estimates. Furthermore, Section \ref{sec:machine_learning_results} shows the results of classical machine learning model, while Section \ref{sec:deep_learning_results} will discuss the results of the deep learning neural networks operating on raw sensor data.






\section{Optimization Goal}
\label{sec:optimization_goal}

This section should outline the processes and decisions which have been taken to determine the best performing system which would produce the most accurate parking space availability estimates. Of course, the first interesting measure when investigating the results of machine learning experiments is the accuracy. However, that measure is not always the most important one, when it comes to solving a specific problem. 

In the parking space detection scenario, which is tackled in this thesis, the overall goal is to derive accurate parking space availability estimates using drive-by park sensing. It is assumed that detailed parking space maps are available, thus it is sufficient to know where cars are parking to also be able to derive vacant spots (detecting a \emph{free space}-class is not enough as it does not determine if it is allowed to park at this spot). Therefore, the most important measures, which should be optimized, are precision and recall of the \emph{parking car}-class. As secondary goals, precision- and recall-measures of the classes \emph{overtaking situation} and \emph{other parking vehicle} should be optimized. \emph{Overtaking situations} are important to detect distractions which prevent deriving accurate parking space availability estimates whereas \emph{other parking vehicles}, such as parking motorcycles, should be detected because they also show that a specific parking spot is occupied. However, these classes have only a minor occurrence in the dataset. This shows that such situations occur relatively rare and therefore are not as important. 
%Furthermore, the performance is expected to be much worse than for the \emph{parking car}-class because of the few segments which are included in the datasets.

To be able to compare two classification results containing recall- and precision measurements, the $f-measure$ (or also called $F_1-score$) has been chosen as comparison measurement. Because it is the harmonic mean of both recall and precision it is well suited for the task. The formula to calculate the $f-measure$ is: $F_1 = 2 \times \frac{precision \times recall}{precision + recall}$.






\section{Machine Learning Results}
\label{sec:machine_learning_results}


\begin{table}


\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c |}
\hline
	&
   \textbf{Accuracy} & 
   \textbf{Recall Parking Car} &
   \textbf{Precision Parking Car} \\
   &
	(full / filtered) & 
	(full / filtered) &
	(full / filtered) \\
\hline
  \textbf{Random Forest} & & & \\
   (entropy, 1000 trees) &
   0.9600 / 0.9608 &
   0.8799 / 0.9239 &
   0.9129 / 0.9377 \\
\hline
  \textbf{Decision Tree} & & & \\
  (gini impurity) &
   0.9486 / 0.9492 &
   0.8492 / 0.8987 &
   0.8753 / 0.9176 \\
\hline
  \textbf{kNN classifier} & & & \\
  (5 nearest neighbors) &
   0.9459 / 0.9457 &
   0.8641 / 0.9175 &
   0.8618 / 0.8941 \\
\hline
  \textbf{Neural Network} & & & \\
  (5 layers - 50 units each, & & & \\
  1 million epochs) &
   0.9440 / 0.9415 &
   0.8479 / 0.9005 &
   0.8529 / 0.8891 \\
\hline
  \textbf{Support Vector Machine} & & & \\
  (kernel: radial basis function) &
   0.9423 / 0.9359 &
   0.7951 / 0.8273 &
   0.9259 / 0.9450 \\
\hline
  \textbf{Naive Bayes} & 
   0.4957 / 0.5886 &
   0.8763 / 0.8822 &
   0.4622 / 0.5915 \\
\hline

\end{tabular}
\egroup
}

\caption{Overall accuracy and results for the \emph{parking car}-class of the best configuration (best set of parameters) of all tested classic machine learning models applied on the full and filtered dataset.}
\label{table:classic_ml_results}
\end{table}


This section discusses the results of the machine learning experiments with common machine learning models using computed feature values as input. As evaluation-method 10-fold cross validation has been chosen (see Section \ref{sec:evaluation_methods}). 
Table \ref{table:classic_ml_results} shows the classification results of the best configurations of all tested machine learning models on the full and filtered dataset sorted on their performance on the f-measure of the \emph{parking car}-class. For each machine learning model, a lot of different parameter combinations have been tested to find the best performing parameter set of each model. The best performing classifier on the \emph{parking car}-class is a random forest classifier using 1000 trees and entropy as criterion for node-splitting at the individual decision trees. It gains an accuracy of about 96\% and a f-measure value of 0.8961 and 0.9307 for the \emph{parking car}-class on the full and filtered dataset, respectively. 

Table \ref{table:best_clf_confusion_matrix_filtered} shows the confusion matrices of the random forest classifier applied on both datasets. The results clearly indicate that all tested models perform better on the parking space map filtered dataset than on the full dataset with all sensed segments. This can be explained due to a more balanced dataset, as a lot of free space segments are filtered out because they are not close to parking zones and thus not relevant.


\begin{table}




\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 11718 & 90 & 0 & 1 \\
\hline
  \textbf{Parking Car} & 244 & 1950 & 21 & 1 \\
\hline
  \textbf{Overtaking Situation} & 63 & 82 & 62 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 54 & 14 & 0 & 1 \\
\hline

\end{tabular}
\egroup
}

\begin{center}
(a) full dataset\\
\end{center}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
   Predicted class $\rightarrow$ &
   \textbf{Free Space} & 
   \textbf{Parking Car} &
   \textbf{Overtaking} &
   \textbf{Other Parking} \\
   True class $\downarrow$ &
	 & 
	 &
	 \textbf{Situation} &
	 \textbf{Vehicle} \\
\hline
  \textbf{Free Space} & 6598 & 81 & 0 & 1 \\
\hline
  \textbf{Parking Car} & 164 & 2017 & 2 & 0 \\
\hline
  \textbf{Overtaking Situation} & 14 & 35 & 17 & 0 \\
\hline
  \textbf{Other Parking Vehicle} & 37 & 18 & 0 & 5 \\
\hline

\end{tabular}
\egroup
}

\begin{center}
(b) filtered dataset\\
\end{center}

\caption{Resulting confusion matrices of the random forest classifier (containing 1000 trees and using entropy as criterion for node-splitting) applied on (a) the full dataset and (b) the filtered dataset.}
\label{table:best_clf_confusion_matrix_filtered}
\end{table}


Another conclusion which can be drawn is that the performance is much worse for the classes \emph{overtaking situation} and \emph{other parking vehicle} than for the \emph{free space}- or \emph{parking car}-class. The best random forest classifier reaches a recall of 0.2575 and a precision of 0.8947 on \emph{overtaking situations}. Therefore, only about a quarter of the overtaking situations are detected. 
On the other hand, the high precision shows that only a low number of false positives are detected as overtaking situations. 
The \emph{other parking vehicle}-class has similar results: a really low recall of 0.0833 and a relatively high precision of 0.8333.
The bad results on the two classes are probably there because of the low number of segments of both classes included in the datasets. Thus, the variety of the data is low and a lot of different situations are not included in the dataset. Therefore, the classifiers cannot learn all different variations of overtaking situations or other parking vehicles. Another explanation is the imbalance in both datasets.






\subsection{Impact of Sampling Techniques in Order to Handle the Dataset Imbalance}

\begin{table}

\resizebox{\textwidth}{!}{%
\centering
\bgroup
\def\arraystretch{1.4}
\begin{tabular}{| r || c | c | c | c |}
\hline
    %& Recall & Prec. & Recall & Prec.\\
    %& PC & PC & OS & OS \\
    & \textbf{No} 
    & \textbf{Over-} 
    & \textbf{Under-} 
    & \textbf{Combination} \\
    & \textbf{sampling} 
    & \textbf{sampling} 
    & \textbf{sampling} 
    & \textbf{Technique} \\
\hline
  \textbf{Overall accuracy} & 0.9608 & 0.9479 & 0.6101 & 0.9349 \\
\hline
  \textbf{Recall Free Space} & 0.9877 & 0.9664 & 0.5752 & 0.9456 \\
\hline
  \textbf{Precision Free Space} & 0.9684 & 0.9772 & 0.9738 & 0.9815 \\
\hline
  \textbf{Recall Parking Car} & 0.9239 & 0.9225 & 0.7091 & 0.9257 \\
\hline
  \textbf{Precision Parking Car} & 0.9377 & 0.9117 & 0.8336 & 0.8813 \\
\hline
  \textbf{Recall Overtaking Sit.} & 0.2575 & 0.3484 & 0.6060 & 0.4393 \\
\hline
  \textbf{Precision Overtaking Sit.} & 0.8947 & 0.3066 & 0.0417 & 0.2989 \\
\hline
  \textbf{Recall Other p. vehicles} & 0.0833 & 0.4666 & 0.9000 & 0.6166 \\
\hline
  \textbf{Precision Other p. vehicles} & 0.8333 & 0.2828 & 0.0242 & 0.2269 \\
\hline

\end{tabular}
\egroup
}

\caption{Comparison of different sampling techniques and their effect on the performance of a random forest classifier on the filtered dataset.}
\label{table:comparison_sampling_techniques}
\end{table}

As the datasets are highly imbalanced, sampling techniques have been tested on their effect to improve the overall accuracy of the classifier and to improve the precision and recall for classes with a low number of samples. Table \ref{table:comparison_sampling_techniques} shows a comparison of different sampling techniques and their impact on different performance measures using the best classifier shown in the previous section (random forest). Experiments with other classifiers have been conducted as well but yielded in worse results on the overall accuracy.

All sampling techniques alter the training data by adding or deleting samples so that it is more balanced. The test data is not altered to get comparable results to the experiments where no sampling has been performed.
Over-sampling creates new synthetic samples from the existing ones, while under-sampling uses clustering techniques to find representatives for a lot of different samples. The combination technique uses both techniques in conjunction to find a compromise sampling solution. For a more detailed description of the different sampling techniques see Section \ref{sec:tested_datasets_and_handling_imbalance}. The goal of all these sampling techniques is to create a dataset where all classes have an equal number of samples. 

The results in Table \ref{table:comparison_sampling_techniques} show that all sampling techniques slightly decrease the performance of the classifier as the overall accuracy is the highest with no sampling at all. Another fact which is shown is that all sampling techniques improve the recall of the classes with a minority of samples (\emph{overtaking situations} and \emph{other parking vehicles}) while at the same time lowering the precision of these classes. This leads to the conclusion that the different sampling techniques make it more likely for the classifier to predict a class which has been a minority class, but using the sampling techniques has an equal amount of samples for the new classification task.

When comparing the sampling techniques, under-sampling clearly performs worst. This can be explained because the under-sampling algorithm deletes most samples in the dataset to create a balanced new dataset. However, this process removes so much information which is contained in the deleted samples that the overall performance decreases drastically. Over-sampling and the combination technique show similar results in terms of accuracy.



different feature sets

Maybe binary classification



\section{Deep Learning Results}
\label{sec:deep_learning_results}

Same as Machine Learning REsults







\section{Using the Segment's Surroundings to improve the Classification Results}

TODO



