\chapter{Prototype Implementation}
\label{chap:referenceimplementation}

As already discussed in chapter \ref{chap:introduction}, sensing a city's parking availability and thus making the parking situation more transparent would be highly beneficial for reducing traffic congestion and greenhouse gas emissions as driver's looking for parking spaces in urban areas could navigate directly to vacant parking spaces close to their destinations. In this thesis a prototype of drive-by sensing using an optical distance sensor was designed, implemented and evaluated.

This chapter will describe the setup and implementation of the prototype. In particular, section \ref{sec:system_design} will discuss the overall envisioned system, the prototype car and the required sensors with their capabilities. In section \ref{sec:experiment_description_data_collection} the experimental setup will be discussed as well as the acquiring of the test dataset through test drives in the city of Linz, Austria. Finally, section \ref{sec:data_processing} will describe the preprocessing of the data, definition of the features and a short description of all used machine learning algorithms with their configurations. 
\todo{update :)}




\section{System design}
\label{sec:system_design}

%This section will describe the envisioned system for the urban parking availability detection system. The proposed system is a mobile sensing system where sensing vehicles try to detect parking cars while driving through the city. The sensing vehicles are equipped with several sensors. Most importantly an optical distance sensor measures the distance to the nearest obstacle on the right side of the road continuously while the vehicle is driving through the city. Furthermore, a GPS receiver determines the corresponding position. 

This section will describe the envisioned system for the urban parking availability detection system. Figure \ref{fig:envisioned_system} shows an overview of how a drive-by sensing system could work. On the left a scene of urban streets is depicted, where cars are parking beside the road and sensing vehicles sense parking cars while they are driving by. The sensing vehicles operate by using an optical distance sensor which is continuously measuring the distance to the nearest obstacle on the right side of the road. Furthermore, a GPS receiver determines the corresponding position. This information is used for the analysis of the parking situation and parking cars and vacant parking spaces are being derived with the recorded sensor data.

The parking analysis can be performed by each sensing vehicle for itself. After obtaining the results, all the derived information may be sent to central server, which then combines the data of all sensing vehicles and computes a parking availability map. This map of free and vacant parking spaces can then be used for showing users the current parking situation (e.g. through a web application) before they even decide if they go by car or by public transport. Furthermore, the information of vacant parking spaces could be used effectively by GPS navigation systems which could direct the driver to a vacant parking space close to his end destination and therefore maybe prevent long parking search times.
%In addition to having a central server, sensing vehicles may send the location of vacant parking spaces in real time to other cars which are searching for parking possibilities. 

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/envisioned-system.eps}
	\caption{Envisioned system of several vehicles driving through the city and sensing its parking availability situation}
	\label{fig:envisioned_system}
\end{figure}

\subsection{Test bed description}
\label{sec:test_bed}

- Testbed description (concrete HW and technical capabilities)

Figure \ref{fig:sensing_car} shows the sensing car and its mounted sensors. 

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/car.jpg}
	\caption{Prototype of the sensing car, which is composed of a LIDAR Lite v3 optical distance sensor, a GPS receiver, a camera for ground truth collection and a Raspberry Pi as processing device}
	\label{fig:sensing_car}
\end{figure}



\begin{table}

\bgroup
\def\arraystretch{1.5}
\begin{tabular}{| r || c | c |}
\hline
   & 
   \textbf{Sampling Frequency} & 
   \textbf{Costs per Sensor} \\
%\hline
\hline
  \textbf{Lidar Lite v3} & 
   ~200 measurements/s &
   \euro{169,00} \\
\hline
  \textbf{Navilock USB} & 
   ~1 measurement/s &
   \euro{74,90} \\
   \textbf{GPS receiver} & & \\
\hline

\end{tabular}
\egroup

\caption{The used sensors}
\label{table:sensors_capabilities}
\end{table}


\section{Experiment description and data collection}
\label{sec:experiment_description_data_collection}
- Description of experiments (scenarios we are interested in: parking car, etc.)
- Data set derived (raw data, size, etc.)
- Map data and camera ground truth data

\section{Data processing}
\label{sec:data_processing}
- Preprocessing, feature definition ...
- Traditional ML Algorithms (incl. a short description of each algorithm and configuration options)
- Deep Learning

\section{Experimental results}
- Results of the different ML approaches, important features, difficult cases, etc.
- Comparison of traditional ML and Deep Learning (cf. our demo)